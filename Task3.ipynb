{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Task3.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPH0leVsMFszpfTrMcLH9fL"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"PhxKOatSFc7Q"},"source":["## **Task 3**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5pLeXRCDFnCu","executionInfo":{"status":"ok","timestamp":1639914446389,"user_tz":-60,"elapsed":26205,"user":{"displayName":"Wiebke Freitag","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17950908629355871951"}},"outputId":"43d65cc4-b89b-43d0-8c14-70da4db5c17d"},"source":["# to access google drive folder\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import numpy as np\n","\n","train_X = np.load(\"/content/drive/MyDrive/CSC3831/train_x.npy\", allow_pickle=True)\n","train_y = np.load(\"/content/drive/MyDrive/CSC3831/train_y.npy\", allow_pickle=True)\n","\n","validate_X = np.load(\"/content/drive/MyDrive/CSC3831/valid_x.npy\", allow_pickle=True)\n","validate_y = np.load(\"/content/drive/MyDrive/CSC3831/valid_y.npy\", allow_pickle=True)\n","\n","test_x = np.load(\"/content/drive/MyDrive/CSC3831/test_x.npy\", allow_pickle=True)\n","test_y = np.load(\"/content/drive/MyDrive/CSC3831/test_y.npy\", allow_pickle=True)\n"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"4gZUdbeUFu8n","executionInfo":{"status":"ok","timestamp":1639914458273,"user_tz":-60,"elapsed":332,"user":{"displayName":"Wiebke Freitag","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17950908629355871951"}}},"source":["import matplotlib.pyplot as plt\n","\n","def image_normalization(arr):\n","    return (arr - arr.min())/(arr.max()-arr.min())\n","\n","def disable_ax_ticks(ax):\n","    ax.set_xticks([])\n","    ax.set_xticks([], minor=True)\n","    ax.set_yticks([])\n","    ax.set_yticks([], minor=True)\n","\n","def show_mnist_examples(x, y):\n","    fig = plt.figure(constrained_layout=True,figsize=(12,9), dpi=100)\n","    gs = fig.add_gridspec(3,4)\n","    main_ax = fig.add_subplot(gs[:3,:3])\n","    fig.suptitle(y)\n","    #main_ax.imshow(np.moveaxis(x, 0, -1))# .imshow(x)\n","    main_ax.imshow(image_normalization(np.moveaxis(x, 0, -1)))\n","    disable_ax_ticks(main_ax)\n","\n","    for j in range(3):\n","      c_ax = fig.add_subplot(gs[j,-1])\n","      subimage = x.copy()\n","      subimage[:j] = 0\n","      subimage[j+1:] = 0\n","      subimage[j] = subimage[j]-subimage[j].min()\n","      c_ax.imshow(image_normalization(np.moveaxis(subimage, 0, -1)))\n","      disable_ax_ticks(c_ax)\n","    plt.show()\n","\n","\n","# normalize and reshape to (-1, 28, 28, 1)\n","def preprocess_image(image):\n","  image = image_normalization(image)\n","  return image.reshape(3, 28, 28, 1)\n"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LzE5h4NzjuPP"},"source":["# Pre-processing the data for model"]},{"cell_type":"code","metadata":{"id":"IX36V0ouj5ez","executionInfo":{"status":"ok","timestamp":1639916985654,"user_tz":-60,"elapsed":208499,"user":{"displayName":"Wiebke Freitag","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17950908629355871951"}}},"source":["from tensorflow.keras.preprocessing import image\n","from tensorflow import keras\n","from tensorflow.keras import Model\n","from tensorflow.keras import layers\n","\n","from tensorflow.keras.layers import Dense, Conv3D, Flatten, Conv2D\n","from tensorflow.keras.models import Sequential\n","import numpy as np\n","import tensorflow as tf\n","\n","num_classes = 20\n","input_shape = (3, 28, 28, 1)\n","\n","batch_size = 80\n","epochs = 15\n","\n","trainX = [preprocess_image(img) for img in train_X]\n","trainX = tf.stack(trainX)\n","\n","validateX = [preprocess_image(img) for img in validate_X]\n","validateX = tf.stack(validateX)\n","\n","testX = [preprocess_image(img) for img in test_x]\n","testX = tf.stack(testX)\n","\n","trainY = keras.utils.to_categorical(train_y, num_classes)\n","validateY = keras.utils.to_categorical(validate_y, num_classes)\n","testY = keras.utils.to_categorical(test_y, num_classes)\n"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Model 1"],"metadata":{"id":"Vdeja2SxgODk"}},{"cell_type":"code","source":["model = keras.Sequential(\n","    [\n","        layers.Conv2D( 25, (3, 3), activation='relu', padding='same', data_format=\"channels_first\", input_shape=input_shape),\n","        layers.Conv2D( 25, (3, 3), activation='relu', padding='same', data_format=\"channels_first\"),      \n","        layers.Flatten(),\n","        layers.Dense(512, activation='relu'),\n","        layers.Dense(256, activation='relu'),\n","        layers.Dense(128, activation='relu'),\n","        layers.Dense(num_classes, activation=\"softmax\"),\n","    ]\n",")\n","\n","model.summary()\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[ \"categorical_accuracy\"])\n","\n","history = model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, validation_data=(validateX, validateY))\n","\n","results = model.evaluate(testX, testY, batch_size=batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cLoEkfA3gcGT","executionInfo":{"status":"ok","timestamp":1639917326500,"user_tz":-60,"elapsed":143945,"user":{"displayName":"Wiebke Freitag","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17950908629355871951"}},"outputId":"3f708104-b8b0-46f7-fc3a-4dd632ba505b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_4 (Conv2D)           (None, 3, 25, 28, 1)      6325      \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 3, 25, 28, 1)      5650      \n","                                                                 \n"," flatten_4 (Flatten)         (None, 2100)              0         \n","                                                                 \n"," dense_16 (Dense)            (None, 512)               1075712   \n","                                                                 \n"," dense_17 (Dense)            (None, 256)               131328    \n","                                                                 \n"," dense_18 (Dense)            (None, 128)               32896     \n","                                                                 \n"," dense_19 (Dense)            (None, 20)                2580      \n","                                                                 \n","=================================================================\n","Total params: 1,254,491\n","Trainable params: 1,254,491\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/15\n","563/563 [==============================] - 7s 12ms/step - loss: 2.1310 - categorical_accuracy: 0.2335 - val_loss: 1.8181 - val_categorical_accuracy: 0.3191\n","Epoch 2/15\n","563/563 [==============================] - 6s 10ms/step - loss: 1.6419 - categorical_accuracy: 0.3894 - val_loss: 1.5028 - val_categorical_accuracy: 0.4552\n","Epoch 3/15\n","563/563 [==============================] - 6s 11ms/step - loss: 1.2039 - categorical_accuracy: 0.5739 - val_loss: 1.0740 - val_categorical_accuracy: 0.6417\n","Epoch 4/15\n","563/563 [==============================] - 6s 11ms/step - loss: 0.7972 - categorical_accuracy: 0.7399 - val_loss: 0.8097 - val_categorical_accuracy: 0.7475\n","Epoch 5/15\n","563/563 [==============================] - 6s 11ms/step - loss: 0.5510 - categorical_accuracy: 0.8276 - val_loss: 0.7088 - val_categorical_accuracy: 0.7870\n","Epoch 6/15\n","563/563 [==============================] - 6s 11ms/step - loss: 0.3907 - categorical_accuracy: 0.8784 - val_loss: 0.6952 - val_categorical_accuracy: 0.7968\n","Epoch 7/15\n","563/563 [==============================] - 6s 11ms/step - loss: 0.2709 - categorical_accuracy: 0.9152 - val_loss: 0.7536 - val_categorical_accuracy: 0.7972\n","Epoch 8/15\n","563/563 [==============================] - 7s 12ms/step - loss: 0.1962 - categorical_accuracy: 0.9376 - val_loss: 0.7433 - val_categorical_accuracy: 0.8151\n","Epoch 9/15\n","563/563 [==============================] - 6s 11ms/step - loss: 0.1358 - categorical_accuracy: 0.9558 - val_loss: 0.8473 - val_categorical_accuracy: 0.8111\n","Epoch 10/15\n","563/563 [==============================] - 6s 10ms/step - loss: 0.1103 - categorical_accuracy: 0.9627 - val_loss: 0.8570 - val_categorical_accuracy: 0.8117\n","Epoch 11/15\n","563/563 [==============================] - 6s 10ms/step - loss: 0.0878 - categorical_accuracy: 0.9702 - val_loss: 0.9244 - val_categorical_accuracy: 0.8109\n","Epoch 12/15\n","563/563 [==============================] - 6s 11ms/step - loss: 0.0768 - categorical_accuracy: 0.9750 - val_loss: 1.0194 - val_categorical_accuracy: 0.8079\n","Epoch 13/15\n","563/563 [==============================] - 6s 10ms/step - loss: 0.0691 - categorical_accuracy: 0.9767 - val_loss: 1.0298 - val_categorical_accuracy: 0.8158\n","Epoch 14/15\n","563/563 [==============================] - 6s 10ms/step - loss: 0.0678 - categorical_accuracy: 0.9776 - val_loss: 1.0017 - val_categorical_accuracy: 0.8182\n","Epoch 15/15\n","563/563 [==============================] - 6s 11ms/step - loss: 0.0600 - categorical_accuracy: 0.9800 - val_loss: 1.0509 - val_categorical_accuracy: 0.8200\n","125/125 [==============================] - 1s 5ms/step - loss: 1.0897 - categorical_accuracy: 0.8165\n"]}]},{"cell_type":"markdown","source":["# Model 2"],"metadata":{"id":"SdOU9khYgVIF"}},{"cell_type":"code","source":["model2 = keras.Sequential(\n","    [      \n","        layers.Flatten(input_shape=input_shape),\n","        layers.Dense(512, activation='relu'),\n","        layers.Dense(256, activation='relu'),\n","        layers.Dense(128, activation='relu'),\n","        layers.Dense(num_classes, activation=\"softmax\"),\n","    ]\n",")\n","\n","model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[ \"categorical_accuracy\"])\n","\n","\n","history = model2.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, validation_data=(validateX, validateY))\n","\n","results = model2.evaluate(testX, testY, batch_size=batch_size)\n","model2.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OSU98DiJgsIn","executionInfo":{"status":"ok","timestamp":1639917735846,"user_tz":-60,"elapsed":84430,"user":{"displayName":"Wiebke Freitag","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17950908629355871951"}},"outputId":"070c9332-7bcc-4c3b-f248-3087fea54d39"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","563/563 [==============================] - 5s 8ms/step - loss: 2.2510 - categorical_accuracy: 0.2222 - val_loss: 2.0089 - val_categorical_accuracy: 0.2917\n","Epoch 2/15\n","563/563 [==============================] - 4s 7ms/step - loss: 1.7829 - categorical_accuracy: 0.3732 - val_loss: 1.6692 - val_categorical_accuracy: 0.4176\n","Epoch 3/15\n","563/563 [==============================] - 5s 8ms/step - loss: 1.4210 - categorical_accuracy: 0.5087 - val_loss: 1.4018 - val_categorical_accuracy: 0.5249\n","Epoch 4/15\n","563/563 [==============================] - 5s 8ms/step - loss: 1.0807 - categorical_accuracy: 0.6334 - val_loss: 1.2144 - val_categorical_accuracy: 0.6035\n","Epoch 5/15\n","563/563 [==============================] - 4s 7ms/step - loss: 0.8044 - categorical_accuracy: 0.7312 - val_loss: 1.0620 - val_categorical_accuracy: 0.6675\n","Epoch 6/15\n","563/563 [==============================] - 4s 7ms/step - loss: 0.5972 - categorical_accuracy: 0.8029 - val_loss: 1.0549 - val_categorical_accuracy: 0.6865\n","Epoch 7/15\n","563/563 [==============================] - 4s 7ms/step - loss: 0.4440 - categorical_accuracy: 0.8546 - val_loss: 1.0588 - val_categorical_accuracy: 0.7081\n","Epoch 8/15\n","563/563 [==============================] - 4s 7ms/step - loss: 0.3277 - categorical_accuracy: 0.8930 - val_loss: 1.1238 - val_categorical_accuracy: 0.7104\n","Epoch 9/15\n","563/563 [==============================] - 4s 8ms/step - loss: 0.2455 - categorical_accuracy: 0.9181 - val_loss: 1.1679 - val_categorical_accuracy: 0.7133\n","Epoch 10/15\n","563/563 [==============================] - 4s 7ms/step - loss: 0.1948 - categorical_accuracy: 0.9353 - val_loss: 1.3190 - val_categorical_accuracy: 0.7052\n","Epoch 11/15\n","563/563 [==============================] - 4s 7ms/step - loss: 0.1631 - categorical_accuracy: 0.9452 - val_loss: 1.4141 - val_categorical_accuracy: 0.7110\n","Epoch 12/15\n","563/563 [==============================] - 4s 8ms/step - loss: 0.1308 - categorical_accuracy: 0.9561 - val_loss: 1.3692 - val_categorical_accuracy: 0.7287\n","Epoch 13/15\n","563/563 [==============================] - 5s 8ms/step - loss: 0.1110 - categorical_accuracy: 0.9628 - val_loss: 1.5064 - val_categorical_accuracy: 0.7186\n","Epoch 14/15\n","563/563 [==============================] - 5s 8ms/step - loss: 0.1080 - categorical_accuracy: 0.9631 - val_loss: 1.5110 - val_categorical_accuracy: 0.7239\n","Epoch 15/15\n","563/563 [==============================] - 5s 8ms/step - loss: 0.1036 - categorical_accuracy: 0.9644 - val_loss: 1.5309 - val_categorical_accuracy: 0.7246\n","125/125 [==============================] - 1s 7ms/step - loss: 1.5666 - categorical_accuracy: 0.7245\n","Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_8 (Flatten)         (None, 2352)              0         \n","                                                                 \n"," dense_32 (Dense)            (None, 512)               1204736   \n","                                                                 \n"," dense_33 (Dense)            (None, 256)               131328    \n","                                                                 \n"," dense_34 (Dense)            (None, 128)               32896     \n","                                                                 \n"," dense_35 (Dense)            (None, 20)                2580      \n","                                                                 \n","=================================================================\n","Total params: 1,371,540\n","Trainable params: 1,371,540\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# Model 3"],"metadata":{"id":"lhN14lDtgWvN"}},{"cell_type":"code","source":["batch_size = 80\n","model = keras.Sequential(\n","    [\n","        layers.Conv2D( 25, (3, 3), activation='relu', padding='same', data_format=\"channels_first\", input_shape=input_shape),\n","        layers.Conv2D( 25, (3, 3), activation='relu', padding='same', data_format=\"channels_first\"),             \n","        layers.Flatten(),\n","        layers.Dense(256, activation='relu'),\n","        layers.Dense(128, activation='relu'),\n","        layers.Dense(num_classes, activation=\"softmax\"),\n","    ]\n",")\n","\n","model.summary()\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[ \"categorical_accuracy\"])\n","\n","history = model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, validation_data=(validateX, validateY))\n","\n","results = model.evaluate(testX, testY, batch_size=batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nxnKJF6YgtWB","executionInfo":{"status":"ok","timestamp":1639917952289,"user_tz":-60,"elapsed":83715,"user":{"displayName":"Wiebke Freitag","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17950908629355871951"}},"outputId":"0083529d-259d-4226-ad68-372ef8aeeda9"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_10\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_9 (Conv2D)           (None, 3, 25, 28, 1)      6325      \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 3, 25, 28, 1)      5650      \n","                                                                 \n"," flatten_10 (Flatten)        (None, 2100)              0         \n","                                                                 \n"," dense_40 (Dense)            (None, 256)               537856    \n","                                                                 \n"," dense_41 (Dense)            (None, 128)               32896     \n","                                                                 \n"," dense_42 (Dense)            (None, 20)                2580      \n","                                                                 \n","=================================================================\n","Total params: 585,307\n","Trainable params: 585,307\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/15\n","563/563 [==============================] - 7s 10ms/step - loss: 2.1718 - categorical_accuracy: 0.2216 - val_loss: 1.8703 - val_categorical_accuracy: 0.3106\n","Epoch 2/15\n","563/563 [==============================] - 6s 10ms/step - loss: 1.6878 - categorical_accuracy: 0.3815 - val_loss: 1.5635 - val_categorical_accuracy: 0.4315\n","Epoch 3/15\n","563/563 [==============================] - 5s 9ms/step - loss: 1.3493 - categorical_accuracy: 0.5181 - val_loss: 1.2848 - val_categorical_accuracy: 0.5513\n","Epoch 4/15\n","563/563 [==============================] - 5s 9ms/step - loss: 1.0299 - categorical_accuracy: 0.6501 - val_loss: 1.0279 - val_categorical_accuracy: 0.6621\n","Epoch 5/15\n","563/563 [==============================] - 5s 9ms/step - loss: 0.7776 - categorical_accuracy: 0.7457 - val_loss: 0.9047 - val_categorical_accuracy: 0.7072\n","Epoch 6/15\n","563/563 [==============================] - 6s 10ms/step - loss: 0.6051 - categorical_accuracy: 0.8036 - val_loss: 0.8712 - val_categorical_accuracy: 0.7248\n","Epoch 7/15\n","563/563 [==============================] - 5s 9ms/step - loss: 0.4710 - categorical_accuracy: 0.8484 - val_loss: 0.8175 - val_categorical_accuracy: 0.7593\n","Epoch 8/15\n","563/563 [==============================] - 5s 9ms/step - loss: 0.3670 - categorical_accuracy: 0.8834 - val_loss: 0.8338 - val_categorical_accuracy: 0.7585\n","Epoch 9/15\n","563/563 [==============================] - 6s 10ms/step - loss: 0.2817 - categorical_accuracy: 0.9084 - val_loss: 0.8644 - val_categorical_accuracy: 0.7667\n","Epoch 10/15\n","563/563 [==============================] - 6s 10ms/step - loss: 0.2143 - categorical_accuracy: 0.9304 - val_loss: 0.8965 - val_categorical_accuracy: 0.7692\n","Epoch 11/15\n","563/563 [==============================] - 6s 10ms/step - loss: 0.1583 - categorical_accuracy: 0.9486 - val_loss: 0.9804 - val_categorical_accuracy: 0.7677\n","Epoch 12/15\n","563/563 [==============================] - 5s 9ms/step - loss: 0.1246 - categorical_accuracy: 0.9595 - val_loss: 1.0514 - val_categorical_accuracy: 0.7702\n","Epoch 13/15\n","563/563 [==============================] - 5s 9ms/step - loss: 0.0986 - categorical_accuracy: 0.9675 - val_loss: 1.2005 - val_categorical_accuracy: 0.7560\n","Epoch 14/15\n","563/563 [==============================] - 5s 9ms/step - loss: 0.0867 - categorical_accuracy: 0.9717 - val_loss: 1.1819 - val_categorical_accuracy: 0.7745\n","Epoch 15/15\n","563/563 [==============================] - 6s 10ms/step - loss: 0.0789 - categorical_accuracy: 0.9737 - val_loss: 1.2670 - val_categorical_accuracy: 0.7663\n","125/125 [==============================] - 1s 5ms/step - loss: 1.2983 - categorical_accuracy: 0.7739\n"]}]},{"cell_type":"markdown","source":["# Model 4"],"metadata":{"id":"1heYc2J_gYbd"}},{"cell_type":"code","source":["model = keras.Sequential(\n","    [\n","        layers.Conv3D( 25, (3, 3, 3), activation='relu', padding='same', data_format=\"channels_first\", input_shape=input_shape),\n","        layers.Conv3D( 25, (3, 3, 3), activation='relu', padding='same', data_format=\"channels_first\", input_shape=input_shape),          \n","        layers.Flatten(),\n","        layers.Dense(256, activation='relu'),\n","        layers.Dense(128, activation='relu'),\n","        layers.Dense(num_classes, activation=\"softmax\"),\n","    ]\n",")\n","\n","model.summary()\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[ \"categorical_accuracy\"])\n","\n","history = model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, validation_data=(validateX, validateY))\n","\n","results = model.evaluate(testX, testY, batch_size=batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7i7SYt6gguVe","executionInfo":{"status":"ok","timestamp":1639920917471,"user_tz":-60,"elapsed":144123,"user":{"displayName":"Wiebke Freitag","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17950908629355871951"}},"outputId":"1a820eb1-ddd8-4b55-c80c-e0907b5ae210"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_14\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv3d_4 (Conv3D)           (None, 25, 28, 28, 1)     2050      \n","                                                                 \n"," flatten_14 (Flatten)        (None, 19600)             0         \n","                                                                 \n"," dense_52 (Dense)            (None, 256)               5017856   \n","                                                                 \n"," dense_53 (Dense)            (None, 128)               32896     \n","                                                                 \n"," dense_54 (Dense)            (None, 20)                2580      \n","                                                                 \n","=================================================================\n","Total params: 5,055,382\n","Trainable params: 5,055,382\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/15\n","563/563 [==============================] - 8s 13ms/step - loss: 2.2282 - categorical_accuracy: 0.2221 - val_loss: 1.9770 - val_categorical_accuracy: 0.2927\n","Epoch 2/15\n","563/563 [==============================] - 7s 13ms/step - loss: 1.7791 - categorical_accuracy: 0.3715 - val_loss: 1.7155 - val_categorical_accuracy: 0.4013\n","Epoch 3/15\n","563/563 [==============================] - 7s 13ms/step - loss: 1.4618 - categorical_accuracy: 0.4986 - val_loss: 1.5300 - val_categorical_accuracy: 0.4849\n","Epoch 4/15\n","563/563 [==============================] - 7s 12ms/step - loss: 1.1691 - categorical_accuracy: 0.6063 - val_loss: 1.4521 - val_categorical_accuracy: 0.5296\n","Epoch 5/15\n","563/563 [==============================] - 7s 12ms/step - loss: 0.8858 - categorical_accuracy: 0.7092 - val_loss: 1.3368 - val_categorical_accuracy: 0.5811\n","Epoch 6/15\n","563/563 [==============================] - 7s 12ms/step - loss: 0.6453 - categorical_accuracy: 0.7913 - val_loss: 1.3760 - val_categorical_accuracy: 0.5887\n","Epoch 7/15\n","563/563 [==============================] - 7s 12ms/step - loss: 0.4584 - categorical_accuracy: 0.8537 - val_loss: 1.4096 - val_categorical_accuracy: 0.6150\n","Epoch 8/15\n","563/563 [==============================] - 7s 12ms/step - loss: 0.3082 - categorical_accuracy: 0.9027 - val_loss: 1.5492 - val_categorical_accuracy: 0.6135\n","Epoch 9/15\n","563/563 [==============================] - 7s 12ms/step - loss: 0.1950 - categorical_accuracy: 0.9404 - val_loss: 1.7343 - val_categorical_accuracy: 0.6128\n","Epoch 10/15\n","563/563 [==============================] - 7s 12ms/step - loss: 0.1321 - categorical_accuracy: 0.9613 - val_loss: 1.8635 - val_categorical_accuracy: 0.6117\n","Epoch 11/15\n","563/563 [==============================] - 7s 13ms/step - loss: 0.1060 - categorical_accuracy: 0.9679 - val_loss: 2.0346 - val_categorical_accuracy: 0.6095\n","Epoch 12/15\n","563/563 [==============================] - 7s 13ms/step - loss: 0.0844 - categorical_accuracy: 0.9743 - val_loss: 2.1636 - val_categorical_accuracy: 0.6148\n","Epoch 13/15\n","563/563 [==============================] - 7s 13ms/step - loss: 0.0895 - categorical_accuracy: 0.9713 - val_loss: 2.3219 - val_categorical_accuracy: 0.6100\n","Epoch 14/15\n","563/563 [==============================] - 7s 12ms/step - loss: 0.0714 - categorical_accuracy: 0.9771 - val_loss: 2.4125 - val_categorical_accuracy: 0.6121\n","Epoch 15/15\n","563/563 [==============================] - 7s 12ms/step - loss: 0.0680 - categorical_accuracy: 0.9778 - val_loss: 2.6371 - val_categorical_accuracy: 0.6091\n","125/125 [==============================] - 1s 7ms/step - loss: 2.6675 - categorical_accuracy: 0.6038\n"]}]}]}